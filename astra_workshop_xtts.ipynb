{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "096b3004",
   "metadata": {},
   "source": [
    "# xTTS on Sagemaker - for Astra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6c11a5",
   "metadata": {},
   "source": [
    "This notebook should be runing in `conda_python3` env, and is designed for Astra Demo only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ec2e51",
   "metadata": {},
   "source": [
    "## Build inference image\n",
    "\n",
    "In this workshop, we'll use the non-deepspeed docker image for inference. If you'd like to enable deepspeed, modify `build_and_push.sh` to build the `Dockerfile-sagemaker-ds` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fd36b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!chmod +x ./*.sh && ./build_and_push.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe8919-0bb9-43c0-8d03-4a2a2a1e9a2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SageMaker endpoint deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11514ade-df1c-4260-8797-83bfc5b279e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "022346938362.dkr.ecr.us-east-1.amazonaws.com/xtts-inference:no-ds-latest\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()  # account_id of the current SageMaker Studio environment\n",
    "bucket = sess.default_bucket()\n",
    "image = \"xtts-inference\"\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "full_image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{image}:no-ds-latest\"\n",
    "print(full_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1663aa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create sagemaker model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c00d88-8abd-423f-bde5-f66d3bc68434",
   "metadata": {},
   "source": [
    "#### 选项1: 使用公开模型\n",
    "\n",
    "The default model used is `tts_models/multilingual/multi-dataset/xtts_v2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd123f2e-f05d-4577-b7b5-0f127049a504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "## for debug only\n",
    "sm_client = boto3.client(service_name='sagemaker')\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    image = full_image_uri\n",
    "    model_name = \"xtts-sagemaker-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "    create_model_response = sm_client.create_model(\n",
    "        ModelName=model_name,\n",
    "        ExecutionRoleArn=role,\n",
    "        Containers=[\n",
    "            {\n",
    "                \"Image\": image,\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    print(create_model_response)\n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835f2b95-710a-4840-87c9-b37b411bb9ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 选项2: 使用自有模型\n",
    "\n",
    "Put the model path info into `CUSTOM_MODEL_PATH` environment variable, the model will be downloaded while launching SageMaker Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2856c336-6651-47c4-af89-ca67dd99dd3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-022346938362/xtts/models/tts_models--multilingual--multi-dataset--xtts_v2/\n"
     ]
    }
   ],
   "source": [
    "# upload model data into s3\n",
    "CUSTOM_MODEL_PATH = f\"s3://{bucket}/xtts/models/tts_models--multilingual--multi-dataset--xtts_v2/\"\n",
    "print(CUSTOM_MODEL_PATH)\n",
    "\n",
    "# replace local folder\n",
    "!aws s3 sync .local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2 $CUSTOM_MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3623fcd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "## for debug only\n",
    "sm_client = boto3.client(service_name='sagemaker')\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    image = full_image_uri\n",
    "    model_name = \"xtts-sagemaker-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "    create_model_response = sm_client.create_model(\n",
    "        ModelName=model_name,\n",
    "        ExecutionRoleArn=role,\n",
    "        Containers=[\n",
    "            {\n",
    "                \"Image\": image,\n",
    "                \"Environment\": {\n",
    "                    \"CUSTOM_MODEL_PATH\": f\"s3://{bucket}/xtts/models/tts_models--multilingual--multi-dataset--xtts_v2\",\n",
    "                    # \"CUSTOM_MODEL_PATH\": \"tts_models/multilingual/multi-dataset/xtts_v2\",\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    print(create_model_response)\n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e913d8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelArn': 'arn:aws:sagemaker:us-east-1:022346938362:model/xtts-sagemaker-2024-12-19-05-46-11', 'ResponseMetadata': {'RequestId': '56f0f5d4-25b2-44cc-950f-099acc8f9b90', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '56f0f5d4-25b2-44cc-950f-099acc8f9b90', 'content-type': 'application/x-amz-json-1.1', 'content-length': '96', 'date': 'Thu, 19 Dec 2024 05:46:11 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "model_name = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159960d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create endpoint configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01b4ba47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpointConfigName = \"xtts-sagemaker-configuration-\"+strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "\n",
    "def create_endpoint_configuration():\n",
    "    create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpointConfigName,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                \"ModelName\": model_name,\n",
    "                \"VariantName\": \"xtts-sagemaker\"+\"-variant\",\n",
    "                \"InstanceType\": \"ml.g5.xlarge\",  # 指定 g5.xlarge 机器\n",
    "                \"InitialInstanceCount\": 1,\n",
    "                \"ModelDataDownloadTimeoutInSeconds\": 1200,\n",
    "                \"ContainerStartupHealthCheckTimeoutInSeconds\": 1200\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    print(create_endpoint_config_response)\n",
    "    return endpointConfigName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d06fb9ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EndpointConfigArn': 'arn:aws:sagemaker:us-east-1:022346938362:endpoint-config/xtts-sagemaker-configuration-2024-12-19-05-46-28', 'ResponseMetadata': {'RequestId': '4692bd02-74c0-4f2d-92a3-56c6df196033', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '4692bd02-74c0-4f2d-92a3-56c6df196033', 'content-type': 'application/x-amz-json-1.1', 'content-length': '129', 'date': 'Thu, 19 Dec 2024 05:46:29 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'xtts-sagemaker-configuration-2024-12-19-05-46-28'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_endpoint_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e35082",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40abb7a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpointName = \"xtts-sagemaker-endpoint\"+strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "\n",
    "def create_endpoint():\n",
    "    create_endpoint_response = sm_client.create_endpoint(\n",
    "        EndpointName=endpointName,\n",
    "        EndpointConfigName=endpointConfigName\n",
    "    )\n",
    "    print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpointName)\n",
    "    print(\"Endpoint Status: \" + resp[\"EndpointStatus\"])\n",
    "    print(\"Waiting for {} endpoint to be in service\".format(\"xtts-sagemaker-endpoint\"))\n",
    "    waiter = sm_client.get_waiter(\"endpoint_in_service\")\n",
    "    waiter.wait(EndpointName=endpointName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adeafb65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:022346938362:endpoint/xtts-sagemaker-endpoint2024-12-19-05-46-35\n",
      "Endpoint Status: Creating\n",
      "Waiting for xtts-sagemaker-endpoint endpoint to be in service\n"
     ]
    }
   ],
   "source": [
    "create_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e41b30b-e8f7-4c7f-853f-7d861c12c543",
   "metadata": {},
   "source": [
    "## Endpoint Test - Stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac28f418-dd4f-4dab-a7cb-412b5048df28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import wave\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# endpointName = \"xtts-sagemaker-endpoint2024-12-19-00-54-34\"  # modify this\n",
    "\n",
    "\n",
    "def invoke_streams_endpoint(smr_client, endpointName, request):\n",
    "    content_type = \"application/json\"\n",
    "    payload = json.dumps(request, ensure_ascii=False)\n",
    "    start = time.time()\n",
    "\n",
    "    response_model = smr_client.invoke_endpoint_with_response_stream(\n",
    "        EndpointName=endpointName,\n",
    "        ContentType=content_type,\n",
    "        Body=payload,\n",
    "    )\n",
    "\n",
    "    print(response_model['ResponseMetadata'])\n",
    "    event_stream = response_model['Body']\n",
    "\n",
    "    result = defaultdict(dict)\n",
    "    for index, event in enumerate(event_stream):\n",
    "        chunk = event['PayloadPart']['Bytes']\n",
    "\n",
    "        result[index] = {\n",
    "            'first_chunk': index == 0,\n",
    "            'bytes': chunk,\n",
    "            'last_chunk': False,\n",
    "            'index': index\n",
    "        }\n",
    "        if index == 0:\n",
    "            print('first chunk latency: ', time.time() - start)\n",
    "\n",
    "        if index < 5:\n",
    "            print(f\"chunk {index} len:\", len(chunk))\n",
    "\n",
    "    # Update the last chunk\n",
    "    last_index = max(result.keys())\n",
    "    result[last_index]['last_chunk'] = True\n",
    "\n",
    "    print(f\"total chunks:\", last_index)\n",
    "\n",
    "    # print(\"result\", dict(result))\n",
    "    return list(result.values())\n",
    "\n",
    "\n",
    "def audio_chunks_to_wav(audio_chunks, output_filename, channels=1, sample_width=2, sample_rate=24000):\n",
    "    with wave.open(output_filename, 'wb') as wav_file:\n",
    "        wav_file.setnchannels(channels)\n",
    "        wav_file.setsampwidth(sample_width)\n",
    "        wav_file.setframerate(sample_rate)\n",
    "\n",
    "        for chunk in audio_chunks:\n",
    "            wav_file.writeframes(chunk['bytes'])\n",
    "\n",
    "    print(f\"WAV file '{output_filename}' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4916e088",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./ref_dayu_2s.wav to s3://sagemaker-us-east-1-022346938362/xtts/wav_ref/ref_dayu_2s.wav\n"
     ]
    }
   ],
   "source": [
    "# Copy reference wav into S3\n",
    "! aws s3 cp ./ref_dayu_2s.wav s3://$bucket/xtts/wav_ref/ref_dayu_2s.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da64eb21-35dd-49c0-9356-9b5833fee9d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtime_sm_client = boto3.client(service_name=\"sagemaker-runtime\", region_name=region)\n",
    "\n",
    "request = {\n",
    "    # \"speaker_name\": \"\",\n",
    "    \"speaker_wav\": [f\"s3://{bucket}/xtts/wav_ref/ref_dayu_2s.wav\"],\n",
    "    \"temperature\": 0.75,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.85,\n",
    "    \"speed\": 1,\n",
    "    \"language_id\": \"en\",\n",
    "    \"text\": \"You can contribute not only with code but with bug reports, comments, questions, answers, or just a simple tweet to spread the word.\",\n",
    "    # \"language_id\": \"zh\",\n",
    "    # \"text\": \"你好，今天天气不错\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b206b8ed-1321-4963-b476-10bff2d985e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RequestId': 'b9b621c6-7d4c-4e8b-89e4-d82438241b2e', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'b9b621c6-7d4c-4e8b-89e4-d82438241b2e', 'x-amzn-invoked-production-variant': 'xtts-sagemaker-variant', 'x-amzn-sagemaker-content-type': 'audio/wav', 'date': 'Thu, 19 Dec 2024 06:40:03 GMT', 'content-type': 'application/vnd.amazon.eventstream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive'}, 'RetryAttempts': 0}\n",
      "first chunk latency:  0.677983283996582\n",
      "chunk 0 len: 480\n",
      "chunk 1 len: 480\n",
      "chunk 2 len: 480\n",
      "chunk 3 len: 480\n",
      "chunk 4 len: 480\n",
      "total chunks: 1016\n"
     ]
    }
   ],
   "source": [
    "response = invoke_streams_endpoint(runtime_sm_client, endpointName, request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8276b56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAV file 'output.wav' has been created.\n"
     ]
    }
   ],
   "source": [
    "audio_chunks_to_wav(response, \"output.wav\", sample_rate=24000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
